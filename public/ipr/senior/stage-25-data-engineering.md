# –≠—Ç–∞–ø 25: Data Engineering & Analytics - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è

## –ó–∞–¥–∞–Ω–∏–µ 25.1: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Data Lake –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### üéØ –¶–µ–ª—å

–°–æ–∑–¥–∞—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –æ–∑–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–±–æ—Ä–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã

### üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:

- [ ] –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (Bronze ‚Üí Silver ‚Üí Gold)
- [ ] –ü–æ—Ç–æ–∫–æ–≤–∞—è –∏ –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- [ ] –°—Ö–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- [ ] –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö
- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

#### –°–ª–æ–∏ –¥–∞–Ω–Ω—ã—Ö:

- [ ] **Bronze (—Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)**: –ò—Å—Ö–æ–¥–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏ –ª–æ–≥–∏
- [ ] **Silver (–æ—á–∏—â–µ–Ω–Ω—ã–µ)**: –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- [ ] **Gold (–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ)**: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- [ ] **–ü–ª–∞—Ç–∏–Ω–æ–≤—ã–π (—Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)**: –ü–æ—Ç–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞—à–±–æ—Ä–¥–æ–≤

### üí° –ü–æ–¥—Å–∫–∞–∑–∫–∏

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Data Lake —Å Delta Lake:**

```typescript
// data-platform/src/schemas/DataSchema.ts
import { z } from "zod";

// –°—Ö–µ–º—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π
export const UserEventSchema = z.object({
  eventId: z.string().uuid(),
  userId: z.string(),
  eventType: z.enum([
    "registration",
    "login",
    "profile_update",
    "deactivation",
  ]),
  timestamp: z.number(),
  properties: z.record(z.any()),
  sessionId: z.string().optional(),
  deviceInfo: z.object({
    userAgent: z.string(),
    ip: z.string(),
    country: z.string().optional(),
  }),
});

export const CryptoTradeEventSchema = z.object({
  eventId: z.string().uuid(),
  userId: z.string(),
  symbol: z.string(),
  side: z.enum(["buy", "sell"]),
  quantity: z.number().positive(),
  price: z.number().positive(),
  timestamp: z.number(),
  orderId: z.string(),
  fee: z.number().nonnegative(),
  metadata: z.record(z.any()),
});

export const PriceDataSchema = z.object({
  symbol: z.string(),
  price: z.number().positive(),
  volume24h: z.number().nonnegative(),
  marketCap: z.number().nonnegative(),
  priceChange24h: z.number(),
  timestamp: z.number(),
  source: z.string(),
  confidence: z.number().min(0).max(1),
});

// –¢–∏–ø—ã –¥–ª—è TypeScript
export type UserEvent = z.infer<typeof UserEventSchema>;
export type CryptoTradeEvent = z.infer<typeof CryptoTradeEventSchema>;
export type PriceData = z.infer<typeof PriceDataSchema>;
```

**ETL –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å Apache Airflow:**

```python
# dags/crypto_data_pipeline.py
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.http.operators.http import SimpleHttpOperator
from airflow.models import Variable
import pandas as pd
import delta
from pyspark.sql import SparkSession

default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'execution_timeout': timedelta(hours=2),
}

dag = DAG(
    'crypto_data_pipeline',
    default_args=default_args,
    description='–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Bronze ‚Üí Silver ‚Üí Gold',
    schedule_interval=timedelta(hours=1),
    catchup=False,
    max_active_runs=1,
    tags=['crypto', 'data-processing', 'etl'],
)

def bronze_to_silver_transformation(**context):
    """–û—á–∏—Å—Ç–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    spark = SparkSession.builder.appName("BronzeToSilver").getOrCreate()

    # –ß—Ç–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Bronze —Å–ª–æ—è
    bronze_df = spark.read.format("delta").load("s3://crypto-datalake/bronze/events/")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    silver_df = bronze_df.filter(
        bronze_df.timestamp.isNotNull() &
        (bronze_df.timestamp > 0) &
        bronze_df.eventType.isin(['registration', 'login', 'trade', 'price_update'])
    ).withColumn(
        "processed_timestamp",
        col("timestamp").cast("timestamp")
    ).withColumn(
        "date_partition",
        date_format(col("processed_timestamp"), "yyyy-MM-dd")
    )

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ eventId
    deduplicated_df = silver_df.dropDuplicates(["eventId"])

    # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –≥–µ–æ–¥–∞–Ω–Ω—ã–º–∏
    enriched_df = deduplicated_df.join(
        broadcast(geo_lookup_df),
        col("deviceInfo.ip") == col("ip_address"),
        "left"
    ).select(
        col("*"),
        col("country_name").alias("user_country"),
        col("city_name").alias("user_city")
    )

    # –ó–∞–ø–∏—Å—å –≤ Silver —Å–ª–æ–π —Å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    enriched_df.write.format("delta").mode("overwrite").partitionBy(
        "date_partition", "eventType"
    ).option("mergeSchema", "true").save("s3://crypto-datalake/silver/events/")

    spark.stop()

    return f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {enriched_df.count()} –∑–∞–ø–∏—Å–µ–π –≤ Silver —Å–ª–æ–π"

def silver_to_gold_aggregation(**context):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤"""
    spark = SparkSession.builder.appName("SilverToGold").getOrCreate()

    # –ß—Ç–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    silver_df = spark.read.format("delta").load("s3://crypto-datalake/silver/events/")

    # –î–Ω–µ–≤–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    daily_user_metrics = silver_df.filter(
        col("eventType").isin(['registration', 'login'])
    ).groupBy(
        "date_partition", "user_country", "eventType"
    ).agg(
        countDistinct("userId").alias("unique_users"),
        count("*").alias("total_events"),
        avg("sessionDuration").alias("avg_session_duration")
    )

    # –¢–æ—Ä–≥–æ–≤—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã
    trading_metrics = silver_df.filter(
        col("eventType") == "trade"
    ).groupBy(
        "date_partition", "symbol"
    ).agg(
        sum("quantity").alias("total_volume"),
        avg("price").alias("avg_price"),
        count("*").alias("trade_count"),
        countDistinct("userId").alias("active_traders")
    )

    # –ó–∞–ø–∏—Å—å –≤ Gold —Å–ª–æ–π
    daily_user_metrics.write.format("delta").mode("overwrite").partitionBy(
        "date_partition"
    ).save("s3://crypto-datalake/gold/user_metrics/")

    trading_metrics.write.format("delta").mode("overwrite").partitionBy(
        "date_partition"
    ).save("s3://crypto-datalake/gold/trading_metrics/")

    spark.stop()

def data_quality_check(**context):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    spark = SparkSession.builder.appName("DataQuality").getOrCreate()

    silver_df = spark.read.format("delta").load("s3://crypto-datalake/silver/events/")

    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    total_records = silver_df.count()
    null_user_ids = silver_df.filter(col("userId").isNull()).count()
    invalid_timestamps = silver_df.filter(
        col("timestamp") < 1640995200  # 2022-01-01
    ).count()

    quality_score = 1 - (null_user_ids + invalid_timestamps) / total_records

    if quality_score < 0.95:
        raise ValueError(f"–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞: {quality_score:.2%}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
    quality_metrics = spark.createDataFrame([{
        "date": context['ds'],
        "total_records": total_records,
        "null_user_ids": null_user_ids,
        "invalid_timestamps": invalid_timestamps,
        "quality_score": quality_score
    }])

    quality_metrics.write.format("delta").mode("append").save(
        "s3://crypto-datalake/monitoring/data_quality/"
    )

    spark.stop()

    return f"–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {quality_score:.2%}"

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á
bronze_to_silver = PythonOperator(
    task_id='bronze_to_silver_transformation',
    python_callable=bronze_to_silver_transformation,
    dag=dag,
)

silver_to_gold = PythonOperator(
    task_id='silver_to_gold_aggregation',
    python_callable=silver_to_gold_aggregation,
    dag=dag,
)

quality_check = PythonOperator(
    task_id='data_quality_check',
    python_callable=data_quality_check,
    dag=dag,
)

# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞–¥–∞—á
bronze_to_silver >> quality_check >> silver_to_gold
```

**–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å Apache Kafka –∏ ClickHouse:**

```typescript
// data-platform/src/streaming/RealTimeProcessor.ts
import { Kafka, Consumer, EachMessagePayload } from "kafkajs";
import { ClickHouse } from "@clickhouse/client";
import { z } from "zod";

export class RealTimeEventProcessor {
  private kafka: Kafka;
  private consumer: Consumer;
  private clickhouse: ClickHouse;
  private batchSize = 1000;
  private batchTimeout = 5000; // 5 —Å–µ–∫—É–Ω–¥
  private eventBatch: any[] = [];

  constructor() {
    this.kafka = new Kafka({
      clientId: "real-time-processor",
      brokers: process.env.KAFKA_BROKERS?.split(",") || ["localhost:9092"],
    });

    this.consumer = this.kafka.consumer({
      groupId: "real-time-analytics",
      sessionTimeout: 30000,
      heartbeatInterval: 3000,
    });

    this.clickhouse = new ClickHouse({
      host: process.env.CLICKHOUSE_HOST || "localhost:8123",
      username: process.env.CLICKHOUSE_USER || "default",
      password: process.env.CLICKHOUSE_PASSWORD || "",
      database: "crypto_analytics",
    });
  }

  async start(): Promise<void> {
    await this.consumer.connect();

    await this.consumer.subscribe({
      topics: ["user-events", "trade-events", "price-events"],
      fromBeginning: false,
    });

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–µ—Ä–∞ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–∞—Ç—á–µ–π
    setInterval(() => {
      if (this.eventBatch.length > 0) {
        this.flushBatch();
      }
    }, this.batchTimeout);

    await this.consumer.run({
      eachMessage: async (payload: EachMessagePayload) => {
        await this.processMessage(payload);
      },
    });
  }

  private async processMessage(payload: EachMessagePayload): Promise<void> {
    const { topic, message } = payload;

    try {
      const event = JSON.parse(message.value?.toString() || "{}");
      const enrichedEvent = await this.enrichEvent(topic, event);

      this.eventBatch.push(enrichedEvent);

      if (this.eventBatch.length >= this.batchSize) {
        await this.flushBatch();
      }
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è:", error);
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Dead Letter Queue
      await this.sendToDeadLetterQueue(topic, message, error);
    }
  }

  private async enrichEvent(topic: string, event: any): Promise<any> {
    const baseEnrichment = {
      ...event,
      processed_timestamp: new Date().toISOString(),
      topic,
      source: "real-time-processor",
    };

    switch (topic) {
      case "user-events":
        return await this.enrichUserEvent(baseEnrichment);
      case "trade-events":
        return await this.enrichTradeEvent(baseEnrichment);
      case "price-events":
        return await this.enrichPriceEvent(baseEnrichment);
      default:
        return baseEnrichment;
    }
  }

  private async enrichUserEvent(event: any): Promise<any> {
    // –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
    const userProfile = await this.getUserProfile(event.userId);

    return {
      ...event,
      user_segment: userProfile?.segment || "unknown",
      user_tier: userProfile?.tier || "basic",
      is_premium: userProfile?.isPremium || false,
    };
  }

  private async enrichTradeEvent(event: any): Promise<any> {
    // –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—É—â–∏–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    const marketData = await this.getCurrentMarketData(event.symbol);

    return {
      ...event,
      market_price: marketData?.price,
      price_deviation: marketData
        ? (event.price - marketData.price) / marketData.price
        : null,
      market_volatility: marketData?.volatility,
    };
  }

  private async flushBatch(): Promise<void> {
    if (this.eventBatch.length === 0) return;

    const batch = [...this.eventBatch];
    this.eventBatch = [];

    try {
      // –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å–æ–±—ã—Ç–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—Å—Ç–∞–≤–∫–∏
      const groupedEvents = this.groupEventsByType(batch);

      for (const [eventType, events] of Object.entries(groupedEvents)) {
        await this.insertToClickHouse(eventType, events);
      }

      console.log(`–û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á –∏–∑ ${batch.length} —Å–æ–±—ã—Ç–∏–π`);
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –±–∞—Ç—á–∞:", error);
      // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–±—ã—Ç–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞—Ç—á –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
      this.eventBatch.unshift(...batch);
    }
  }

  private async insertToClickHouse(
    eventType: string,
    events: any[]
  ): Promise<void> {
    const tableName = this.getTableName(eventType);

    await this.clickhouse.insert({
      table: tableName,
      values: events,
      format: "JSONEachRow",
    });
  }

  private getTableName(eventType: string): string {
    const tableMap: Record<string, string> = {
      "user-events": "user_events_realtime",
      "trade-events": "trade_events_realtime",
      "price-events": "price_events_realtime",
    };

    return tableMap[eventType] || "unknown_events";
  }

  private groupEventsByType(events: any[]): Record<string, any[]> {
    return events.reduce(
      (groups, event) => {
        const type = event.topic || "unknown";
        if (!groups[type]) {
          groups[type] = [];
        }
        groups[type].push(event);
        return groups;
      },
      {} as Record<string, any[]>
    );
  }

  private async getUserProfile(userId: string): Promise<any> {
    // –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    const cacheKey = `user:${userId}`;
    // –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø—É—â–µ–Ω–∞ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
    return { segment: "active", tier: "premium", isPremium: true };
  }

  private async getCurrentMarketData(symbol: string): Promise<any> {
    // –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    const result = await this.clickhouse.query({
      query: `
        SELECT 
          price,
          stddevPop(price) OVER (
            ORDER BY timestamp 
            ROWS BETWEEN 100 PRECEDING AND CURRENT ROW
          ) as volatility
        FROM price_events_realtime 
        WHERE symbol = {symbol:String}
        ORDER BY timestamp DESC 
        LIMIT 1
      `,
      query_params: { symbol },
    });

    return result.json().then((data) => data[0]);
  }
}

// –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
const processor = new RealTimeEventProcessor();
processor.start().catch(console.error);
```

### ‚ùì –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è

1. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö**: –ö–∞–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–∞–µ—Ç –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–∑–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö?
2. **–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**: –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Ç–æ–∫–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–º–µ—Å—Ç–æ –ø–∞–∫–µ—Ç–Ω–æ–π?
3. **–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö**: –ö–∞–∫ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω—è—Ö?
4. **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ö–∞–∫ –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö?

### üîç –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏

- [ ] **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–∑–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö** (40): –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å–ª–æ–µ–≤ –¥–∞–Ω–Ω—ã—Ö
- [ ] **ETL –ø—Ä–æ—Ü–µ—Å—Å—ã** (30): –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
- [ ] **–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** (20): –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- [ ] **–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö** (10): –°–∏—Å—Ç–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

---

## –ó–∞–¥–∞–Ω–∏–µ 25.2: –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ —Å ClickHouse

### üéØ –¶–µ–ª—å

–°–æ–∑–¥–∞—Ç—å –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö

### üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

#### –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:

- [ ] –ö–æ–ª–æ–Ω–æ—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- [ ] –ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
- [ ] –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- [ ] –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- [ ] API –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞—à–±–æ—Ä–¥–æ–≤

### üí° –ü–æ–¥—Å–∫–∞–∑–∫–∏

**ClickHouse —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü:**

```sql
-- –¢–∞–±–ª–∏—Ü–∞ —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
CREATE TABLE user_events_local (
    event_id String,
    user_id String,
    event_type LowCardinality(String),
    timestamp DateTime64(3),
    properties String,
    session_id Nullable(String),
    device_info String,
    user_country LowCardinality(String),
    user_city String,
    date Date MATERIALIZED toDate(timestamp)
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (event_type, user_id, timestamp)
SETTINGS index_granularity = 8192;

-- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
CREATE TABLE user_events ON CLUSTER crypto_cluster AS user_events_local
ENGINE = Distributed('crypto_cluster', default, user_events_local, rand());

-- –ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –¥–Ω–µ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
CREATE MATERIALIZED VIEW user_daily_metrics_mv
TO user_daily_metrics
AS SELECT
    toDate(timestamp) as date,
    event_type,
    user_country,
    count() as event_count,
    uniq(user_id) as unique_users,
    uniq(session_id) as unique_sessions,
    avg(JSONExtractFloat(properties, 'session_duration')) as avg_session_duration
FROM user_events_local
GROUP BY date, event_type, user_country;

-- –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
CREATE TABLE user_daily_metrics (
    date Date,
    event_type LowCardinality(String),
    user_country LowCardinality(String),
    event_count UInt64,
    unique_users UInt64,
    unique_sessions UInt64,
    avg_session_duration Float64
) ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, event_type, user_country);

-- –¢–∞–±–ª–∏—Ü–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π
CREATE TABLE trade_events_local (
    event_id String,
    user_id String,
    symbol LowCardinality(String),
    side Enum8('buy' = 1, 'sell' = 2),
    quantity Decimal64(8),
    price Decimal64(8),
    timestamp DateTime64(3),
    order_id String,
    fee Decimal64(8),
    market_price Nullable(Decimal64(8)),
    price_deviation Nullable(Float64),
    date Date MATERIALIZED toDate(timestamp)
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (symbol, timestamp, user_id)
SETTINGS index_granularity = 8192;

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
ALTER TABLE trade_events_local ADD INDEX idx_user_id user_id TYPE bloom_filter(0.01) GRANULARITY 1;
ALTER TABLE trade_events_local ADD INDEX idx_symbol symbol TYPE set(100) GRANULARITY 1;
```

**–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π API —Å–µ—Ä–≤–∏—Å:**

```typescript
// analytics-service/src/controllers/AnalyticsController.ts
import { ClickHouse } from "@clickhouse/client";
import { z } from "zod";

const AnalyticsQuerySchema = z.object({
  dateFrom: z.string().regex(/^\d{4}-\d{2}-\d{2}$/),
  dateTo: z.string().regex(/^\d{4}-\d{2}-\d{2}$/),
  groupBy: z.enum(["day", "week", "month"]).default("day"),
  metrics: z.array(z.enum(["users", "sessions", "trades", "volume"])),
  filters: z
    .object({
      country: z.string().optional(),
      symbol: z.string().optional(),
      userSegment: z.string().optional(),
    })
    .optional(),
});

export class AnalyticsController {
  private clickhouse: ClickHouse;

  constructor() {
    this.clickhouse = new ClickHouse({
      host: process.env.CLICKHOUSE_HOST || "localhost:8123",
      username: process.env.CLICKHOUSE_USER || "default",
      password: process.env.CLICKHOUSE_PASSWORD || "",
      database: "crypto_analytics",
    });
  }

  async getUserMetrics(request: Request): Promise<Response> {
    const queryParams = AnalyticsQuerySchema.parse(request.query);

    const timeGrouping = this.getTimeGrouping(queryParams.groupBy);
    const whereClause = this.buildWhereClause(queryParams);

    const query = `
      SELECT 
        ${timeGrouping} as period,
        ${this.buildMetricsSelection(queryParams.metrics)},
        user_country
      FROM user_daily_metrics
      ${whereClause}
      GROUP BY period, user_country
      ORDER BY period DESC, user_country
      LIMIT 10000
    `;

    const result = await this.clickhouse.query({
      query,
      query_params: {
        date_from: queryParams.dateFrom,
        date_to: queryParams.dateTo,
      },
    });

    const data = await result.json();

    return new Response(
      JSON.stringify({
        data,
        metadata: {
          query_time: result.statistics?.elapsed || 0,
          rows_read: result.statistics?.rows_read || 0,
          total_rows: data.length,
        },
      }),
      {
        headers: { "Content-Type": "application/json" },
      }
    );
  }

  async getTradingMetrics(request: Request): Promise<Response> {
    const queryParams = AnalyticsQuerySchema.parse(request.query);

    const query = `
      WITH trading_stats AS (
        SELECT 
          ${this.getTimeGrouping(queryParams.groupBy)} as period,
          symbol,
          count() as trade_count,
          sum(quantity) as total_volume,
          sum(quantity * price) as total_value,
          uniq(user_id) as active_traders,
          avg(price) as avg_price,
          stddevPop(price) as price_volatility
        FROM trade_events_local
        WHERE date BETWEEN {date_from:String} AND {date_to:String}
          ${queryParams.filters?.symbol ? "AND symbol = {symbol:String}" : ""}
        GROUP BY period, symbol
      )
      SELECT 
        period,
        symbol,
        trade_count,
        total_volume,
        total_value,
        active_traders,
        avg_price,
        price_volatility,
        total_value / lag(total_value) OVER (PARTITION BY symbol ORDER BY period) as volume_growth
      FROM trading_stats
      ORDER BY period DESC, total_value DESC
    `;

    const result = await this.clickhouse.query({
      query,
      query_params: {
        date_from: queryParams.dateFrom,
        date_to: queryParams.dateTo,
        ...(queryParams.filters?.symbol && {
          symbol: queryParams.filters.symbol,
        }),
      },
    });

    return new Response(JSON.stringify(await result.json()), {
      headers: { "Content-Type": "application/json" },
    });
  }

  async getRealTimeMetrics(): Promise<Response> {
    // –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    const query = `
      SELECT 
        toStartOfHour(timestamp) as hour,
        count() as events_per_hour,
        uniq(user_id) as unique_users_per_hour,
        avg(JSONExtractFloat(properties, 'response_time')) as avg_response_time
      FROM user_events_local
      WHERE timestamp >= now() - INTERVAL 24 HOUR
      GROUP BY hour
      ORDER BY hour DESC
    `;

    const result = await this.clickhouse.query({ query });

    return new Response(
      JSON.stringify({
        realtime_metrics: await result.json(),
        last_updated: new Date().toISOString(),
      }),
      {
        headers: { "Content-Type": "application/json" },
      }
    );
  }

  private getTimeGrouping(groupBy: string): string {
    switch (groupBy) {
      case "day":
        return "toDate(date)";
      case "week":
        return "toMonday(date)";
      case "month":
        return "toStartOfMonth(date)";
      default:
        return "toDate(date)";
    }
  }

  private buildWhereClause(params: any): string {
    let whereClause =
      "WHERE date BETWEEN {date_from:String} AND {date_to:String}";

    if (params.filters?.country) {
      whereClause += " AND user_country = {country:String}";
    }

    return whereClause;
  }

  private buildMetricsSelection(metrics: string[]): string {
    const metricMap: Record<string, string> = {
      users: "sum(unique_users) as total_users",
      sessions: "sum(unique_sessions) as total_sessions",
      events: "sum(event_count) as total_events",
    };

    return metrics
      .filter((metric) => metricMap[metric])
      .map((metric) => metricMap[metric])
      .join(", ");
  }
}
```

### ‚ùì –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è

1. **–ö–æ–ª–æ–Ω–æ—á–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞**: –ö–∞–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–∞–µ—Ç ClickHouse –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤?
2. **–ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è**: –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MV –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏?
3. **–ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö?
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤**: –ö–∞–∫–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –≤ ClickHouse?

---

## üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —ç—Ç–∞–ø–∞ 25

| –ö—Ä–∏—Ç–µ—Ä–∏–π                     | –ë–∞–ª–ª—ã   | –û–ø–∏—Å–∞–Ω–∏–µ                                   |
| ---------------------------- | ------- | ------------------------------------------ |
| **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–∑–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö** | 50      | Data Lake layers, —Å—Ö–µ–º—ã, –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **ETL –ø–∞–π–ø–ª–∞–π–Ω—ã**            | 40      | Airflow DAGs, –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö              |
| **–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**      | 30      | Kafka, real-time processing                |
| **–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞**  | 40      | ClickHouse, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤    |
| **–ò—Ç–æ–≥–æ**                    | **160** | –ú–∏–Ω–∏–º—É–º 112 –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —ç—Ç–∞–ø—É 26        |

### üéØ –°–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —ç—Ç–∞–ø–∞ 25 –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ **–≠—Ç–∞–ø—É 26: AI/ML Integration**.
